---
title: â€˜Running jobs on HiPerGator'
date: 2019-05-02
permalink: /posts/2019/05/blog-post-4/
tags:
  - hipergator
  - bash
  - running jobs
---

Running jobs on HiPerGator
------
HiPerGator moved from a PBS to Slurm(Simple Linux Utility for Resource Management), in 2015? or 2016?, not sure.  
But let's break down the sample bash script line by line , which you can [download here](Add link to the bash script)

`#!/bin/sh`: Important first line that informs it is a shell script.  
`#SBATCH --job-name=JOBNAME`: Name of the job (can be changed by the user).  
`#SBATCH --mail-type=ALL` : # Mail events that the user chooses to receive. Options include: (NONE, BEGIN, END, FAIL, ALL).  
    


     
    #SBATCH --mail-user=pinedae@ufl.edu # Where to send mail
#SBATCH --cpus-per-task=4 # Number of cores: Can also use -c=4
#SBATCH --mem-per-cpu=1gb # Per processor memory can be increase 8gb
#SBATCH -t 18:00:00     # Walltime
#SBATCH -o raxml_output.%j.out # Name output file
#SBATCH
#SBATCH --account=paulay

pwd; hostname; date
echo Working directory is $SLURM_SUBMIT_DIR
cd $SLURM_SUBMIT_DIR

echo There are $SLURM_CPUS_ON_NODE cores available.

module load raxml
